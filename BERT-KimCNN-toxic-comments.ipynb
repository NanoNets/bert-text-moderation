{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "import torch\n",
    "import pickle\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    def __init__(self, id, text, labels=None):\n",
    "        self.id = id\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_examples(train_file):\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    ids = train_df['id'].values\n",
    "    text = train_df['comment_text'].values\n",
    "    labels = train_df[train_df.columns[2:]].values\n",
    "    examples = []\n",
    "    for i in range(len(train_df)):\n",
    "        examples.append(InputExample(ids[i], text[i], labels=labels[i]))\n",
    "    return examples\n",
    "\n",
    "def get_test_examples(test_file):\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    ids = test_df['id'].values\n",
    "    text = test_df['comment_text'].values\n",
    "    examples = []\n",
    "    for i in range(len(test_df)):\n",
    "        examples.append(InputExample(ids[i], text[i], labels=[]))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_examples(examples, max_seq_len, tokenizer):\n",
    "    features = []\n",
    "    for i,example in enumerate(examples):\n",
    "        tokens = tokenizer.tokenize(example.text)\n",
    "        if len(tokens) > max_seq_len - 2:\n",
    "            tokens = tokens[:(max_seq_len - 2)]\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        padding = [0] * (max_seq_len - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        assert len(input_ids) == max_seq_len\n",
    "        assert len(input_mask) == max_seq_len\n",
    "        assert len(segment_ids) == max_seq_len\n",
    "        label_ids = [float(label) for label in example.labels]\n",
    "        features.append(InputFeatures(input_ids=input_ids,\n",
    "                                      input_mask=input_mask,\n",
    "                                      segment_ids=segment_ids,\n",
    "                                      label_ids=label_ids))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_features(features):\n",
    "    input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.float)\n",
    "    dataset = TensorDataset(input_ids,\n",
    "                            input_mask,\n",
    "                            segment_ids,\n",
    "                            label_ids)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, dropout=0.1, kernel_num=3, kernel_sizes=[2,3,4], num_labels=2):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.embed_num = embed_num\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.embed = nn.Embedding(self.embed_num, self.embed_dim)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, self.kernel_num, (k, self.embed_dim)) for k in self.kernel_sizes])\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.classifier = nn.Linear(len(self.kernel_sizes)*self.kernel_num, self.num_labels)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        output = inputs.unsqueeze(1)\n",
    "        output = [nn.functional.relu(conv(output)).squeeze(3) for conv in self.convs]\n",
    "        output = [nn.functional.max_pool1d(i, i.size(2)).squeeze(2) for i in output]\n",
    "        output = torch.cat(output, 1)\n",
    "        output = self.dropout(output)\n",
    "        logits = self.classifier(output)\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(type='cuda')\n",
    "pretrained_weights = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)\n",
    "basemodel = BertModel.from_pretrained(pretrained_weights)\n",
    "basemodel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 256\n",
    "train_file = 'train.csv'\n",
    "train_examples = get_train_examples(train_file)\n",
    "train_features = get_features_from_examples(train_examples, seq_len, tokenizer)\n",
    "train_dataset = get_dataset_from_features(train_features)\n",
    "\n",
    "\n",
    "train_val_split = 0.33\n",
    "train_size = int(len(train_dataset)*(1-train_val_split))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "batch = 8\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = seq_len \n",
    "embed_dim = basemodel.config.hidden_size \n",
    "dropout = basemodel.config.hidden_dropout_prob\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2,3,4]\n",
    "num_labels = 6\n",
    "\n",
    "model = KimCNN(embed_num, embed_dim, dropout=dropout, kernel_num=kernel_num, kernel_sizes=kernel_sizes, num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-5\n",
    "epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "for i in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        with torch.no_grad():\n",
    "            inputs,_ = basemodel(input_ids, segment_ids, input_mask)\n",
    "        loss = model(inputs, label_ids)\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()        \n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        val_input_ids, val_input_mask, val_segment_ids, val_label_ids = batch\n",
    "        with torch.no_grad():\n",
    "            val_inputs,_ = basemodel(val_input_ids, val_segment_ids, val_input_mask)\n",
    "        val_loss = model(val_inputs, val_label_ids)\n",
    "        logits = model(val_inputs)\n",
    "        y_true.append(val_label_ids)\n",
    "        y_pred.append(logits)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).float().cpu().detach().numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).float().cpu().detach().numpy()\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        fpr[label], tpr[label], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[label] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    print('ROC AUC per label:')\n",
    "    for label in labels:\n",
    "        print(label, ': ', roc_auc[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './trained_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
